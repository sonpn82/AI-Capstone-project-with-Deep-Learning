{"cells":[{"cell_type":"markdown","source":["<a href=\"http://cocl.us/pytorch_link_top\">\n","    <img src=\"https://s3-api.us-geo.objectstorage.softlayer.net/cf-courses-data/CognitiveClass/DL0110EN/notebook_images%20/Pytochtop.png\" width=\"750\" alt=\"IBM Product \" />\n","</a> \n"],"metadata":{}},{"cell_type":"markdown","source":["<img src=\"https://s3-api.us-geo.objectstorage.softlayer.net/cf-courses-data/CognitiveClass/DL0110EN/notebook_images%20/cc-logo-square.png\" width=\"200\" alt=\"cognitiveclass.ai logo\" />\n"],"metadata":{}},{"cell_type":"markdown","source":["<h1><h1>Pre-trained-Models with PyTorch </h1>\n"],"metadata":{}},{"cell_type":"markdown","source":["In this lab, you will use pre-trained models to classify between the negative and positive samples; you will be provided with the dataset object. The particular pre-trained model will be resnet18; you will have three questions: \n","\n","<ul>\n","<li>change the output layer</li>\n","<li> train the model</li> \n","<li>  identify  several  misclassified samples</li> \n"," </ul>\n","You will take several screenshots of your work and share your notebook. \n"],"metadata":{}},{"cell_type":"markdown","source":["<h2>Table of Contents</h2>\n"],"metadata":{}},{"cell_type":"markdown","source":["<div class=\"alert alert-block alert-info\" style=\"margin-top: 20px\">\n","\n","<ul>\n","    <li><a href=\"#download_data\"> Download Data</a></li>\n","    <li><a href=\"#auxiliary\"> Imports and Auxiliary Functions </a></li>\n","    <li><a href=\"#data_class\"> Dataset Class</a></li>\n","    <li><a href=\"#Question_1\">Question 1</a></li>\n","    <li><a href=\"#Question_2\">Question 2</a></li>\n","    <li><a href=\"#Question_3\">Question 3</a></li>\n","</ul>\n","<p>Estimated Time Needed: <strong>120 min</strong></p>\n"," </div>\n","<hr>\n"],"metadata":{}},{"cell_type":"markdown","source":["<h2 id=\"download_data\">Download Data</h2>\n"],"metadata":{}},{"cell_type":"markdown","source":["Download the dataset and unzip the files in your data directory, unlike the other labs, all the data will be deleted after you close  the lab, this may take some time:\n"],"metadata":{}},{"cell_type":"code","execution_count":null,"source":["!wget https://s3-api.us-geo.objectstorage.softlayer.net/cf-courses-data/CognitiveClass/DL0321EN/data/images/Positive_tensors.zip "],"outputs":[],"metadata":{}},{"cell_type":"code","execution_count":null,"source":["!unzip -q Positive_tensors.zip "],"outputs":[],"metadata":{}},{"cell_type":"code","execution_count":null,"source":["! wget https://s3-api.us-geo.objectstorage.softlayer.net/cf-courses-data/CognitiveClass/DL0321EN/data/images/Negative_tensors.zip\r\n","!unzip -q Negative_tensors.zip"],"outputs":[],"metadata":{}},{"cell_type":"markdown","source":["We will install torchvision:\n"],"metadata":{}},{"cell_type":"code","execution_count":null,"source":["!pip install torchvision"],"outputs":[],"metadata":{}},{"cell_type":"markdown","source":["<h2 id=\"auxiliary\">Imports and Auxiliary Functions</h2>\n"],"metadata":{}},{"cell_type":"markdown","source":["The following are the libraries we are going to use for this lab. The <code>torch.manual_seed()</code> is for forcing the random function to give the same number every time we try to recompile it.\n"],"metadata":{}},{"cell_type":"code","execution_count":1,"source":["# These are the libraries will be used for this lab.\r\n","import torchvision.models as models\r\n","from PIL import Image\r\n","import pandas\r\n","from torchvision import transforms\r\n","import torch.nn as nn\r\n","import time\r\n","import torch \r\n","import matplotlib.pylab as plt\r\n","import numpy as np\r\n","from torch.utils.data import Dataset, DataLoader\r\n","import h5py\r\n","import os\r\n","import glob\r\n","torch.manual_seed(0)"],"outputs":[{"output_type":"execute_result","data":{"text/plain":["<torch._C.Generator at 0x60d4a70>"]},"metadata":{},"execution_count":1}],"metadata":{}},{"cell_type":"code","execution_count":2,"source":["from matplotlib.pyplot import imshow\r\n","import matplotlib.pylab as plt\r\n","from PIL import Image\r\n","import pandas as pd\r\n","import os"],"outputs":[],"metadata":{}},{"cell_type":"markdown","source":["<!--Empty Space for separating topics-->\n"],"metadata":{}},{"cell_type":"markdown","source":["<h2 id=\"data_class\">Dataset Class</h2>\n"],"metadata":{}},{"cell_type":"markdown","source":[" This dataset class is essentially the same dataset you build in the previous section, but to speed things up, we are going to use tensors instead of jpeg images. Therefor for each iteration, you will skip the reshape step, conversion step to tensors and normalization step.\n"],"metadata":{}},{"cell_type":"code","execution_count":3,"source":["# Create your own dataset object\r\n","\r\n","class Dataset(Dataset):\r\n","\r\n","    # Constructor\r\n","    def __init__(self,transform=None,train=True):\r\n","        directory=r\"C:\\Users\\hp\\Downloads\\Data\"\r\n","        positive=\"Positive_tensors\"\r\n","        negative='Negative_tensors'\r\n","\r\n","        positive_file_path=os.path.join(directory,positive)\r\n","        negative_file_path=os.path.join(directory,negative)\r\n","        positive_files=[os.path.join(positive_file_path,file) for file in os.listdir(positive_file_path) if file.endswith(\".pt\")]\r\n","        negative_files=[os.path.join(negative_file_path,file) for file in os.listdir(negative_file_path) if file.endswith(\".pt\")]\r\n","        number_of_samples=len(positive_files)+len(negative_files)\r\n","        self.all_files=[None]*number_of_samples\r\n","        self.all_files[::2]=positive_files\r\n","        self.all_files[1::2]=negative_files \r\n","        # The transform is goint to be used on image\r\n","        self.transform = transform\r\n","        #torch.LongTensor\r\n","        self.Y=torch.zeros([number_of_samples]).type(torch.LongTensor)\r\n","        self.Y[::2]=1\r\n","        self.Y[1::2]=0\r\n","        \r\n","        if train:\r\n","            self.all_files=self.all_files[0:30000]\r\n","            self.Y=self.Y[0:30000]\r\n","            self.len=len(self.all_files)\r\n","        else:\r\n","            self.all_files=self.all_files[30000:]\r\n","            self.Y=self.Y[30000:]\r\n","            self.len=len(self.all_files)     \r\n","       \r\n","    # Get the length\r\n","    def __len__(self):\r\n","        return self.len\r\n","    \r\n","    # Getter\r\n","    def __getitem__(self, idx):\r\n","               \r\n","        image=torch.load(self.all_files[idx])\r\n","        y=self.Y[idx]\r\n","                  \r\n","        # If there is any transform method, apply it onto the image\r\n","        if self.transform:\r\n","            image = self.transform(image)\r\n","\r\n","        return image, y\r\n","    \r\n","print(\"done\")"],"outputs":[{"output_type":"stream","name":"stdout","text":["done\n"]}],"metadata":{}},{"cell_type":"markdown","source":["We create two dataset objects, one for the training data and one for the validation data.\n"],"metadata":{}},{"cell_type":"code","execution_count":5,"source":["train_dataset = Dataset(train=True)\r\n","validation_dataset = Dataset(train=False)\r\n","print(\"done\")"],"outputs":[{"output_type":"stream","name":"stdout","text":["done\n"]}],"metadata":{}},{"cell_type":"markdown","source":["<h2 id=\"Question_1\">Question 1</h2>\n"],"metadata":{}},{"cell_type":"markdown","source":["<b>Prepare a pre-trained resnet18 model :</b>\n"],"metadata":{}},{"cell_type":"markdown","source":["<b>Step 1</b>: Load the pre-trained model <code>resnet18</code> Set the parameter <code>pretrained</code> to true:\n"],"metadata":{}},{"cell_type":"code","execution_count":6,"source":["# Step 1: Load the pre-trained model resnet18\r\n","\r\n","model = models.resnet18(pretrained=True)"],"outputs":[{"output_type":"stream","name":"stderr","text":["Downloading: \"https://download.pytorch.org/models/resnet18-5c106cde.pth\" to C:\\Users\\hp/.cache\\torch\\hub\\checkpoints\\resnet18-5c106cde.pth\n","100%|██████████| 44.7M/44.7M [00:08<00:00, 5.33MB/s]\n"]}],"metadata":{}},{"cell_type":"markdown","source":["<b>Step 2</b>: Set the attribute <code>requires_grad</code> to <code>False</code>. As a result, the parameters will not be affected by training.\n"],"metadata":{}},{"cell_type":"code","execution_count":8,"source":["# Step 2: Set the parameter cannot be trained for the pre-trained model\r\n","for param in model.parameters():\r\n","    param.requires_grad = False\r\n"],"outputs":[],"metadata":{}},{"cell_type":"markdown","source":["<code>resnet18</code> is used to classify 1000 different objects; as a result, the last layer has 1000 outputs.  The 512 inputs come from the fact that the previously hidden layer has 512 outputs. \n"],"metadata":{}},{"cell_type":"markdown","source":["<b>Step 3</b>: Replace the output layer <code>model.fc</code> of the neural network with a <code>nn.Linear</code> object, to classify 2 different classes. For the parameters <code>in_features </code> remember the last hidden layer has 512 neurons.\n"],"metadata":{}},{"cell_type":"code","execution_count":9,"source":["model.fc = nn.Linear(512, 2)"],"outputs":[],"metadata":{}},{"cell_type":"markdown","source":["Print out the model in order to show whether you get the correct answer.<br> <b>(Your peer reviewer is going to mark based on what you print here.)</b>\n"],"metadata":{}},{"cell_type":"code","execution_count":10,"source":["print(model)"],"outputs":[{"output_type":"stream","name":"stdout","text":["ResNet(\n","  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n","  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","  (relu): ReLU(inplace=True)\n","  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n","  (layer1): Sequential(\n","    (0): BasicBlock(\n","      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (1): BasicBlock(\n","      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","  )\n","  (layer2): Sequential(\n","    (0): BasicBlock(\n","      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (downsample): Sequential(\n","        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (1): BasicBlock(\n","      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","  )\n","  (layer3): Sequential(\n","    (0): BasicBlock(\n","      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (downsample): Sequential(\n","        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (1): BasicBlock(\n","      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","  )\n","  (layer4): Sequential(\n","    (0): BasicBlock(\n","      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (downsample): Sequential(\n","        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (1): BasicBlock(\n","      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","  )\n","  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n","  (fc): Linear(in_features=512, out_features=2, bias=True)\n",")\n"]}],"metadata":{}},{"cell_type":"markdown","source":["# Check GPU"],"metadata":{}},{"cell_type":"code","execution_count":11,"source":["torch.cuda.is_available()\r\n","torch.cuda.empty_cache()"],"outputs":[],"metadata":{}},{"cell_type":"code","execution_count":12,"source":["# create a device\r\n","device = torch.device('cuda:0')\r\n","device"],"outputs":[{"output_type":"execute_result","data":{"text/plain":["device(type='cuda', index=0)"]},"metadata":{},"execution_count":12}],"metadata":{}},{"cell_type":"markdown","source":["<h2 id=\"Question_2\">Question 2: Train the Model</h2>\n"],"metadata":{}},{"cell_type":"markdown","source":["In this question you will train your, model:\n"],"metadata":{}},{"cell_type":"markdown","source":["<b>Step 1</b>: Create a cross entropy criterion function \n"],"metadata":{}},{"cell_type":"code","execution_count":14,"source":["# Step 1: Create the loss function\r\n","\r\n","criterion = nn.CrossEntropyLoss()"],"outputs":[],"metadata":{}},{"cell_type":"markdown","source":["<b>Step 2</b>: Create a training loader and validation loader object, the batch size should have 100 samples each.\n"],"metadata":{}},{"cell_type":"code","execution_count":15,"source":["train_loader = DataLoader(dataset=train_dataset, batch_size=100)\r\n","validation_loader = DataLoader(dataset=validation_dataset, batch_size=100)"],"outputs":[],"metadata":{}},{"cell_type":"markdown","source":["<b>Step 3</b>: Use the following optimizer to minimize the loss \n"],"metadata":{}},{"cell_type":"code","execution_count":16,"source":["optimizer = torch.optim.Adam([parameters  for parameters in model.parameters() if parameters.requires_grad],lr=0.001)"],"outputs":[],"metadata":{}},{"cell_type":"code","execution_count":17,"source":["# GPU\r\n","model.to(device)"],"outputs":[{"output_type":"execute_result","data":{"text/plain":["ResNet(\n","  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n","  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","  (relu): ReLU(inplace=True)\n","  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n","  (layer1): Sequential(\n","    (0): BasicBlock(\n","      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (1): BasicBlock(\n","      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","  )\n","  (layer2): Sequential(\n","    (0): BasicBlock(\n","      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (downsample): Sequential(\n","        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (1): BasicBlock(\n","      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","  )\n","  (layer3): Sequential(\n","    (0): BasicBlock(\n","      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (downsample): Sequential(\n","        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (1): BasicBlock(\n","      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","  )\n","  (layer4): Sequential(\n","    (0): BasicBlock(\n","      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (downsample): Sequential(\n","        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (1): BasicBlock(\n","      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","  )\n","  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n","  (fc): Linear(in_features=512, out_features=2, bias=True)\n",")"]},"metadata":{},"execution_count":17}],"metadata":{}},{"cell_type":"markdown","source":["<!--Empty Space for separating topics-->\n"],"metadata":{}},{"cell_type":"markdown","source":["**Complete the following code to calculate  the accuracy on the validation data for one epoch; this should take about 45 minutes. Make sure you calculate the accuracy on the validation data.**\n"],"metadata":{}},{"cell_type":"code","execution_count":18,"source":["n_epochs=1\r\n","loss_list=[]\r\n","accuracy_list=[]\r\n","correct=0\r\n","N_test=len(validation_dataset)\r\n","N_train=len(train_dataset)\r\n","start_time = time.time()\r\n","#n_epochs\r\n","\r\n","Loss=0\r\n","start_time = time.time()\r\n","for epoch in range(n_epochs):\r\n","    for x, y in train_loader:\r\n","\r\n","        model.train() \r\n","        x, y = x.to(device), y.to(device)\r\n","\r\n","        #clear gradient \r\n","        optimizer.zero_grad()\r\n","\r\n","        #make a prediction \r\n","        z = model(x)\r\n","   \r\n","        # calculate loss \r\n","        loss = criterion(z, y)\r\n","    \r\n","        # calculate gradients of parameters\r\n","        loss.backward() \r\n","        \r\n","        # update parameters\r\n","        optimizer.step() \r\n","        \r\n","        loss_list.append(loss.data)\r\n","\r\n","    correct=0\r\n","    for x_test, y_test in validation_loader:\r\n","        # set model to eval \r\n","        model.eval()\r\n","        x_test, y_test = x_test.to(device), y_test.to(device)\r\n","\r\n","        #make a prediction \r\n","        z = model(x_test)\r\n","\r\n","        #find max \r\n","        _, yhat = torch.max(z.data, 1)\r\n","       \r\n","        #Calculate misclassified  samples in mini-batch \r\n","        correct += (yhat==y_test).sum().item()\r\n","        \r\n","   \r\n","    accuracy = correct/N_test\r\n","    accuracy_list.append(accuracy)\r\n","\r\n"],"outputs":[],"metadata":{}},{"cell_type":"markdown","source":["<b>Print out the Accuracy and plot the loss stored in the list <code>loss_list</code> for every iteration and take a screen shot.</b>\n"],"metadata":{}},{"cell_type":"code","execution_count":19,"source":["accuracy"],"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.9943"]},"metadata":{},"execution_count":19}],"metadata":{}},{"cell_type":"code","execution_count":21,"source":["loss_list_cpu = []  # copy from device to host memory\r\n","for ll in loss_list:\r\n","    loss_list_cpu.append(ll.cpu())"],"outputs":[],"metadata":{}},{"cell_type":"code","execution_count":22,"source":["plt.plot(loss_list_cpu)\r\n","plt.xlabel(\"iteration\")\r\n","plt.ylabel(\"loss\")\r\n","plt.show()\r\n"],"outputs":[{"output_type":"display_data","data":{"text/plain":["<Figure size 432x288 with 1 Axes>"],"image/png":"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"},"metadata":{"needs_background":"light"}}],"metadata":{}},{"cell_type":"markdown","source":["<h2 id=\"Question_3\">Question 3:Find the misclassified samples</h2> \n"],"metadata":{}},{"cell_type":"markdown","source":["<b>Identify the first four misclassified samples using the validation data:</b>\n"],"metadata":{}},{"cell_type":"code","execution_count":29,"source":["count = 0\r\n","i = 0\r\n","\r\n","for x, y in DataLoader(dataset=validation_dataset, batch_size=1):\r\n","        \r\n","    x, y = x.to(device), y.to(device)\r\n","    z = model(x)\r\n","    _, yhat = torch.max(z, 1)\r\n","    if yhat != y:\r\n","        print('misclassified at i=', i, ' y predict=', yhat, ' y actual=', y)\r\n","        count += 1\r\n","    if count >= 5:\r\n","        break  \r\n","    i+=1"],"outputs":[{"output_type":"stream","name":"stdout","text":["misclassified at i= 22  y predict= tensor([0], device='cuda:0')  y actual= tensor([1], device='cuda:0')\n","misclassified at i= 101  y predict= tensor([1], device='cuda:0')  y actual= tensor([0], device='cuda:0')\n","misclassified at i= 182  y predict= tensor([0], device='cuda:0')  y actual= tensor([1], device='cuda:0')\n","misclassified at i= 213  y predict= tensor([1], device='cuda:0')  y actual= tensor([0], device='cuda:0')\n","misclassified at i= 264  y predict= tensor([0], device='cuda:0')  y actual= tensor([1], device='cuda:0')\n"]}],"metadata":{}},{"cell_type":"markdown","source":["<a href=\"https://dataplatform.cloud.ibm.com/docs/content/wsj/analyze-data/share-notebooks.html\"> CLICK HERE </a> Click here to see how to share your notebook.\n"],"metadata":{}},{"cell_type":"markdown","source":["<h2>About the Authors:</h2> \n","\n","<a href=\"https://www.linkedin.com/in/joseph-s-50398b136/\">Joseph Santarcangelo</a> has a PhD in Electrical Engineering, his research focused on using machine learning, signal processing, and computer vision to determine how videos impact human cognition. Joseph has been working for IBM since he completed his PhD.\n"],"metadata":{}},{"cell_type":"markdown","source":["## Change Log\n","\n","| Date (YYYY-MM-DD) | Version | Changed By | Change Description                                          |\n","| ----------------- | ------- | ---------- | ----------------------------------------------------------- |\n","| 2020-09-21        | 2.0     | Shubham    | Migrated Lab to Markdown and added to course repo in GitLab |\n","\n","<hr>\n","\n","## <h3 align=\"center\"> © IBM Corporation 2020. All rights reserved. <h3/>\n"],"metadata":{}},{"cell_type":"markdown","source":["Copyright © 2018 <a href=\"cognitiveclass.ai?utm_source=bducopyrightlink&utm_medium=dswb&utm_campaign=bdu\">cognitiveclass.ai</a>. This notebook and its source code are released under the terms of the <a href=\"https://bigdatauniversity.com/mit-license/\">MIT License</a>.\n"],"metadata":{}}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3.8.8 64-bit ('base': conda)"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.8"},"interpreter":{"hash":"c0f70214c0dd213f07f54ee5d6e0ea644bdbba35113c9bfe8aaa0d1db03ad5dd"}},"nbformat":4,"nbformat_minor":2}