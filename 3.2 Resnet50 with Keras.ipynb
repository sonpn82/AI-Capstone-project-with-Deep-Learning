{
    "cells": [
        {
            "cell_type": "markdown",
            "source": [
                "# IBM Developer Skills Network"
            ],
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "# Resnet50 with Keras"
            ],
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "# Pretrained model"
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "source": [
                "from keras.preprocessing.image import ImageDataGenerator"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "source": [
                "import keras\r\n",
                "from keras.models import Sequential\r\n",
                "from keras.layers import Dense"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "source": [
                "from keras.applications import ResNet50\r\n",
                "from keras.applications.resnet50 import preprocess_input"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [
                "# link https://s3-api.us-geo.objectstorage.softlayer.net/cf-courses-data/CognitiveClass/DL0321EN/data/concrete_data_week3.zip"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "## Define Global Constants"
            ],
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "Here, we will define constants that we will be using throughout the rest of the lab. \r\n",
                "\r\n",
                "1.  We are obviously dealing with two classes, so _num_classes_ is 2. \r\n",
                "2.  The ResNet50 model was built and trained using images of size (224 x 224). Therefore, we will have to resize our images from (227 x 227) to (224 x 224).\r\n",
                "3.  We will training and validating the model using batches of 100 images."
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "source": [
                "num_classes = 2\r\n",
                "image_resize = 224\r\n",
                "batch_size_training = 100\r\n",
                "batch_size_validation = 100"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "## Construct ImageDataGenerator Instances"
            ],
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "In order to instantiate an ImageDataGenerator instance, we will set the **preprocessing_function** argument to _preprocess_input_ which we imported from **keras.applications.resnet50** in order to preprocess our images the same way the images used to train ResNet50 model were processed.\r\n"
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 22,
            "source": [
                "data_generator = ImageDataGenerator(\r\n",
                "    preprocessing_function=preprocess_input,\r\n",
                ")"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 50,
            "source": [
                "train_generator = data_generator.flow_from_directory(\r\n",
                "                                        r'C:\\Users\\hp\\Downloads\\concrete_data_week3\\train',\r\n",
                "                                        target_size=(image_resize, image_resize),\r\n",
                "                                        batch_size = batch_size_training,\r\n",
                "                                        class_mode = 'categorical')\r\n",
                "\r\n",
                "      \r\n",
                "\r\n",
                "validation_generator = data_generator.flow_from_directory(\r\n",
                "                                        r'C:\\Users\\hp\\Downloads\\concrete_data_week3\\valid',\r\n",
                "                                        target_size=(image_resize, image_resize),\r\n",
                "                                        batch_size = batch_size_validation,\r\n",
                "                                        class_mode = 'categorical')"
            ],
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "Found 30001 images belonging to 2 classes.\n",
                        "Found 10001 images belonging to 2 classes.\n"
                    ]
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 18,
            "source": [],
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "Found 10001 images belonging to 2 classes.\n"
                    ]
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "# Build Compile and Fit Model"
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 42,
            "source": [
                "model = Sequential()"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "Next, we will add the ResNet50 pre-trained model to out model. However, note that we don't want to include the top layer or the output layer of the pre-trained model. We actually want to define our own output layer and train it so that it is optimized for our image dataset. In order to leave out the output layer of the pre-trained model, we will use the argument _include_top_ and set it to **False**."
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 43,
            "source": [
                "model.add(ResNet50(\r\n",
                "    include_top=False,\r\n",
                "    pooling='avg',\r\n",
                "    weights='imagenet',\r\n",
                "    ))"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "Then, we will define our output layer as a **Dense** layer, that consists of two nodes and uses the **Softmax** function as the activation function."
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 44,
            "source": [
                "# softmax output layer\r\n",
                "model.add(Dense(num_classes, activation='softmax'))"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 45,
            "source": [
                "model.layers"
            ],
            "outputs": [
                {
                    "output_type": "execute_result",
                    "data": {
                        "text/plain": [
                            "[<tensorflow.python.keras.engine.functional.Functional at 0x489e33d0>,\n",
                            " <tensorflow.python.keras.layers.core.Dense at 0x4ab473a0>]"
                        ]
                    },
                    "metadata": {},
                    "execution_count": 45
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 46,
            "source": [
                "model.layers[0].layers"
            ],
            "outputs": [
                {
                    "output_type": "execute_result",
                    "data": {
                        "text/plain": [
                            "[<tensorflow.python.keras.engine.input_layer.InputLayer at 0x3ca77160>,\n",
                            " <tensorflow.python.keras.layers.convolutional.ZeroPadding2D at 0x47c5cd90>,\n",
                            " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x47c5ce20>,\n",
                            " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x47c109d0>,\n",
                            " <tensorflow.python.keras.layers.core.Activation at 0x47c63ee0>,\n",
                            " <tensorflow.python.keras.layers.convolutional.ZeroPadding2D at 0x47c63fd0>,\n",
                            " <tensorflow.python.keras.layers.pooling.MaxPooling2D at 0x47c703a0>,\n",
                            " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x3f041e80>,\n",
                            " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x3f0416a0>,\n",
                            " <tensorflow.python.keras.layers.core.Activation at 0x3f052400>,\n",
                            " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x3f07b7c0>,\n",
                            " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x3f082df0>,\n",
                            " <tensorflow.python.keras.layers.core.Activation at 0x3f0acdf0>,\n",
                            " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x47c6a4c0>,\n",
                            " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x3f0ac460>,\n",
                            " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x3f03cb80>,\n",
                            " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x3f0bf370>,\n",
                            " <tensorflow.python.keras.layers.merge.Add at 0x3f0e63d0>,\n",
                            " <tensorflow.python.keras.layers.core.Activation at 0x3f0e6be0>,\n",
                            " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x3f0e61f0>,\n",
                            " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x3f0f6ca0>,\n",
                            " <tensorflow.python.keras.layers.core.Activation at 0x3f11f4f0>,\n",
                            " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x3f11f8e0>,\n",
                            " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x3f12cca0>,\n",
                            " <tensorflow.python.keras.layers.core.Activation at 0x404ff4f0>,\n",
                            " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x404ff2e0>,\n",
                            " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x4050f670>,\n",
                            " <tensorflow.python.keras.layers.merge.Add at 0x40537220>,\n",
                            " <tensorflow.python.keras.layers.core.Activation at 0x40537940>,\n",
                            " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x40537f10>,\n",
                            " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x40548310>,\n",
                            " <tensorflow.python.keras.layers.core.Activation at 0x40572850>,\n",
                            " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x40572460>,\n",
                            " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x40583f10>,\n",
                            " <tensorflow.python.keras.layers.core.Activation at 0x405a4880>,\n",
                            " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x405a45b0>,\n",
                            " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x405b4580>,\n",
                            " <tensorflow.python.keras.layers.merge.Add at 0x405deeb0>,\n",
                            " <tensorflow.python.keras.layers.core.Activation at 0x405dea90>,\n",
                            " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x40727bb0>,\n",
                            " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x40727460>,\n",
                            " <tensorflow.python.keras.layers.core.Activation at 0x4075e9d0>,\n",
                            " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x4075e3d0>,\n",
                            " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x40770400>,\n",
                            " <tensorflow.python.keras.layers.core.Activation at 0x407968e0>,\n",
                            " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x406f6820>,\n",
                            " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x40796790>,\n",
                            " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x40701040>,\n",
                            " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x407a9f10>,\n",
                            " <tensorflow.python.keras.layers.merge.Add at 0x407cb880>,\n",
                            " <tensorflow.python.keras.layers.core.Activation at 0x407cbee0>,\n",
                            " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x407cd880>,\n",
                            " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x407fcf40>,\n",
                            " <tensorflow.python.keras.layers.core.Activation at 0x40804dc0>,\n",
                            " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x40804d90>,\n",
                            " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x37d3bac0>,\n",
                            " <tensorflow.python.keras.layers.core.Activation at 0x3ca78e50>,\n",
                            " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x47c10490>,\n",
                            " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x3ca2cdf0>,\n",
                            " <tensorflow.python.keras.layers.merge.Add at 0x3ca99760>,\n",
                            " <tensorflow.python.keras.layers.core.Activation at 0x3ca99130>,\n",
                            " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x3ca973a0>,\n",
                            " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x3ca97a30>,\n",
                            " <tensorflow.python.keras.layers.core.Activation at 0x3ca392b0>,\n",
                            " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x3ca39f40>,\n",
                            " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x3ca4e8e0>,\n",
                            " <tensorflow.python.keras.layers.core.Activation at 0x3ca0b580>,\n",
                            " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x3ca0b760>,\n",
                            " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x3ca012e0>,\n",
                            " <tensorflow.python.keras.layers.merge.Add at 0x3c9dc550>,\n",
                            " <tensorflow.python.keras.layers.core.Activation at 0x3c9dcbb0>,\n",
                            " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x3c9d9220>,\n",
                            " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x3c9d1b80>,\n",
                            " <tensorflow.python.keras.layers.core.Activation at 0x3c94bc40>,\n",
                            " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x3c8c3070>,\n",
                            " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x3c9bbdf0>,\n",
                            " <tensorflow.python.keras.layers.core.Activation at 0x3c986070>,\n",
                            " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x3c980790>,\n",
                            " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x3c97abe0>,\n",
                            " <tensorflow.python.keras.layers.merge.Add at 0x3c8fe670>,\n",
                            " <tensorflow.python.keras.layers.core.Activation at 0x3c81c460>,\n",
                            " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x3c922c40>,\n",
                            " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x3c9220a0>,\n",
                            " <tensorflow.python.keras.layers.core.Activation at 0x3c8caa30>,\n",
                            " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x3c8ca5b0>,\n",
                            " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x3c8c04c0>,\n",
                            " <tensorflow.python.keras.layers.core.Activation at 0x3c817280>,\n",
                            " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x3c81c7c0>,\n",
                            " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x3c817e50>,\n",
                            " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x3c81c1c0>,\n",
                            " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x3c8a1d90>,\n",
                            " <tensorflow.python.keras.layers.merge.Add at 0x3c8208e0>,\n",
                            " <tensorflow.python.keras.layers.core.Activation at 0x3c820b20>,\n",
                            " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x3c820f40>,\n",
                            " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x3c6f54f0>,\n",
                            " <tensorflow.python.keras.layers.core.Activation at 0x3c6fba60>,\n",
                            " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x3c857d00>,\n",
                            " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x3c851280>,\n",
                            " <tensorflow.python.keras.layers.core.Activation at 0x3c838d90>,\n",
                            " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x3c834b80>,\n",
                            " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x3c82c3a0>,\n",
                            " <tensorflow.python.keras.layers.merge.Add at 0x3bb987c0>,\n",
                            " <tensorflow.python.keras.layers.core.Activation at 0x3c744d00>,\n",
                            " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x3c747100>,\n",
                            " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x3c74a670>,\n",
                            " <tensorflow.python.keras.layers.core.Activation at 0x3c6f3d00>,\n",
                            " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x3c750250>,\n",
                            " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x3c678ee0>,\n",
                            " <tensorflow.python.keras.layers.core.Activation at 0x3c70aee0>,\n",
                            " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x3c70ad60>,\n",
                            " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x3c70b640>,\n",
                            " <tensorflow.python.keras.layers.merge.Add at 0x3c673df0>,\n",
                            " <tensorflow.python.keras.layers.core.Activation at 0x3c68ab20>,\n",
                            " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x3c68aca0>,\n",
                            " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x3c6ab7f0>,\n",
                            " <tensorflow.python.keras.layers.core.Activation at 0x3c6dbf70>,\n",
                            " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x3c6db160>,\n",
                            " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x3cc18bb0>,\n",
                            " <tensorflow.python.keras.layers.core.Activation at 0x408e2250>,\n",
                            " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x408e22e0>,\n",
                            " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x41433550>,\n",
                            " <tensorflow.python.keras.layers.merge.Add at 0x4145da90>,\n",
                            " <tensorflow.python.keras.layers.core.Activation at 0x4145dd60>,\n",
                            " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x4145d790>,\n",
                            " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x41464dc0>,\n",
                            " <tensorflow.python.keras.layers.core.Activation at 0x41499c40>,\n",
                            " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x41499610>,\n",
                            " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x414c5c40>,\n",
                            " <tensorflow.python.keras.layers.core.Activation at 0x414cc070>,\n",
                            " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x414cc4c0>,\n",
                            " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x414de670>,\n",
                            " <tensorflow.python.keras.layers.merge.Add at 0x41505760>,\n",
                            " <tensorflow.python.keras.layers.core.Activation at 0x41505d90>,\n",
                            " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x41505190>,\n",
                            " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x415180d0>,\n",
                            " <tensorflow.python.keras.layers.core.Activation at 0x4751b640>,\n",
                            " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x47520df0>,\n",
                            " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x4752ad00>,\n",
                            " <tensorflow.python.keras.layers.core.Activation at 0x47555190>,\n",
                            " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x475555e0>,\n",
                            " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x47565340>,\n",
                            " <tensorflow.python.keras.layers.merge.Add at 0x4758db20>,\n",
                            " <tensorflow.python.keras.layers.core.Activation at 0x4758df70>,\n",
                            " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x475c9ca0>,\n",
                            " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x475d4e50>,\n",
                            " <tensorflow.python.keras.layers.core.Activation at 0x475fdc40>,\n",
                            " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x47a78220>,\n",
                            " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x4760ef70>,\n",
                            " <tensorflow.python.keras.layers.core.Activation at 0x47a80df0>,\n",
                            " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x4758da00>,\n",
                            " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x47a852e0>,\n",
                            " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x4759fbe0>,\n",
                            " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x47a8dd90>,\n",
                            " <tensorflow.python.keras.layers.merge.Add at 0x47abc400>,\n",
                            " <tensorflow.python.keras.layers.core.Activation at 0x47abc100>,\n",
                            " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x47ac1160>,\n",
                            " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x47c8f9d0>,\n",
                            " <tensorflow.python.keras.layers.core.Activation at 0x47c95f10>,\n",
                            " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x47c95100>,\n",
                            " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x47ca94c0>,\n",
                            " <tensorflow.python.keras.layers.core.Activation at 0x484a0ca0>,\n",
                            " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x484a0910>,\n",
                            " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x484a7f10>,\n",
                            " <tensorflow.python.keras.layers.merge.Add at 0x487f3ee0>,\n",
                            " <tensorflow.python.keras.layers.core.Activation at 0x487f3a30>,\n",
                            " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x487fa3d0>,\n",
                            " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x48827550>,\n",
                            " <tensorflow.python.keras.layers.core.Activation at 0x4882f8b0>,\n",
                            " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x4882f1c0>,\n",
                            " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x4883f490>,\n",
                            " <tensorflow.python.keras.layers.core.Activation at 0x48867760>,\n",
                            " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x48867e20>,\n",
                            " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x4887b0d0>,\n",
                            " <tensorflow.python.keras.layers.merge.Add at 0x4889c430>,\n",
                            " <tensorflow.python.keras.layers.core.Activation at 0x4889c520>,\n",
                            " <tensorflow.python.keras.layers.pooling.GlobalAveragePooling2D at 0x488a2700>]"
                        ]
                    },
                    "metadata": {},
                    "execution_count": 46
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "Since the ResNet50 model has already been trained, then we want to tell our model not to bother with training the ResNet part, but to train only our dense output layer. To do that, we run the following."
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 47,
            "source": [
                "model.layers[0].trainable = False"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "And now using the _summary_ attribute of the model, we can see how many parameters we will need to optimize in order to train the output layer."
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 48,
            "source": [
                "model.summary()"
            ],
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "Model: \"sequential\"\n",
                        "_________________________________________________________________\n",
                        "Layer (type)                 Output Shape              Param #   \n",
                        "=================================================================\n",
                        "resnet50 (Functional)        (None, 2048)              23587712  \n",
                        "_________________________________________________________________\n",
                        "dense_3 (Dense)              (None, 2)                 4098      \n",
                        "=================================================================\n",
                        "Total params: 23,591,810\n",
                        "Trainable params: 4,098\n",
                        "Non-trainable params: 23,587,712\n",
                        "_________________________________________________________________\n"
                    ]
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 49,
            "source": [
                "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "Before we are able to start the training process, with an ImageDataGenerator, we will need to define how many steps compose an epoch. Typically, that is the number of images divided by the batch size. Therefore, we define our steps per epoch as follows:"
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 51,
            "source": [
                "steps_per_epoch_training = len(train_generator)\r\n",
                "steps_per_epoch_validation = len(validation_generator)\r\n",
                "num_epochs = 2"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "Finally, we are ready to start training our model. Unlike a conventional deep learning training were data is not streamed from a directory, with an ImageDataGenerator where data is augmented in batches, we use the **fit_generator** method.\r\n"
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 52,
            "source": [
                "fit_history = model.fit_generator(\r\n",
                "                train_generator,\r\n",
                "                steps_per_epoch=steps_per_epoch_training,\r\n",
                "                validation_data=validation_generator,\r\n",
                "                validation_steps=steps_per_epoch_validation,\r\n",
                "                verbose=1,\r\n",
                ")"
            ],
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "WARNING:tensorflow:From <ipython-input-52-d76532ca96aa>:1: Model.fit_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
                        "Instructions for updating:\n",
                        "Please use Model.fit, which supports generators.\n",
                        "301/301 [==============================] - 1991s 7s/step - loss: 0.0277 - accuracy: 0.9905 - val_loss: 0.0071 - val_accuracy: 0.9982\n"
                    ]
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "Since training can take a long time when building deep learning models, it is always a good idea to save your model once the training is complete if you believe you will be using the model again later. You will be using this model in the next module, so go ahead and save your model."
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 53,
            "source": [
                "model.save('classifier_resnet_model.h5')"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [],
            "outputs": [],
            "metadata": {}
        }
    ],
    "metadata": {
        "orig_nbformat": 4,
        "language_info": {
            "name": "python",
            "version": "3.8.8",
            "mimetype": "text/x-python",
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "pygments_lexer": "ipython3",
            "nbconvert_exporter": "python",
            "file_extension": ".py"
        },
        "kernelspec": {
            "name": "python3",
            "display_name": "Python 3.8.8 64-bit ('base': conda)"
        },
        "interpreter": {
            "hash": "c0f70214c0dd213f07f54ee5d6e0ea644bdbba35113c9bfe8aaa0d1db03ad5dd"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}